{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title"
   },
   "source": [
    "# B-cos PIP-Net Comprehensive Visualizations\n",
    "\n",
    "This notebook provides comprehensive visualizations for B-cos PIP-Net including:\n",
    "\n",
    "## 🔍 What we visualize:\n",
    "1. **Input Images**: Original RGB images from 6-channel input\n",
    "2. **Learned Part Prototypes**: Spatial activation maps showing where prototypes activate\n",
    "3. **B-cos Spatial Contributions**: Gradient-based explanation maps showing spatial contributions\n",
    "\n",
    "## 🎯 Key Features:\n",
    "- **Interactive Exploration**: Examine individual images and their prototype activations\n",
    "- **Spatial Understanding**: See exactly where in the image each prototype is active\n",
    "- **Gradient-based Explanations**: B-cos contribution maps show positive/negative evidence\n",
    "- **Comprehensive Views**: Combined visualizations for complete interpretability\n",
    "\n",
    "## 📊 Visualization Types:\n",
    "- Single image comprehensive view\n",
    "- Prototype activation heatmaps\n",
    "- B-cos spatial contribution maps\n",
    "- Multi-image comparison grids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## 1. Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check_gpu"
   },
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name()}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_deps"
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install torch torchvision torchaudio\n",
    "!pip install matplotlib seaborn\n",
    "!pip install opencv-python\n",
    "!pip install pillow numpy\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clone_repo"
   },
   "outputs": [],
   "source": [
    "# Clone the repository (if not already done)\n",
    "import os\n",
    "if not os.path.exists('improved-Bcos-PIPNet'):\n",
    "    !git clone https://github.com/your-username/improved-Bcos-PIPNet.git\n",
    "%cd improved-Bcos-PIPNet\n",
    "\n",
    "# Initialize submodules\n",
    "!git submodule update --init --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup_paths"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add source directories to Python path\n",
    "sys.path.append('src')\n",
    "sys.path.append('B-cos')\n",
    "sys.path.append('PIPNet')\n",
    "\n",
    "# Verify visualization module exists\n",
    "print(\"Current directory:\", os.getcwd())\n",
    "print(\"Visualization module exists:\", os.path.exists('src/visualizations.py'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upload_model"
   },
   "source": [
    "## 2. Upload Fine-tuned Model\n",
    "\n",
    "Upload your fine-tuned B-cos PIP-Net model from the previous fine-tuning step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "upload_model_file"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "# Create model directory\n",
    "os.makedirs('./models', exist_ok=True)\n",
    "\n",
    "print(\"Please upload your fine-tuned B-cos PIP-Net model (.pth file):\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Move uploaded file to models directory\n",
    "model_path = None\n",
    "for filename in uploaded.keys():\n",
    "    if filename.endswith('.pth'):\n",
    "        os.rename(filename, f'./models/{filename}')\n",
    "        model_path = f'./models/{filename}'\n",
    "        print(f\"Model saved to: {model_path}\")\n",
    "        break\n",
    "\n",
    "if model_path is None:\n",
    "    # Use default path for testing\n",
    "    model_path = './models/finetuned_model_final.pth'\n",
    "    print(f\"No model uploaded. Will use: {model_path}\")\n",
    "    print(\"Note: Make sure to upload your fine-tuned model for actual visualization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "import_modules"
   },
   "source": [
    "## 3. Import Modules and Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imports"
   },
   "outputs": [],
   "source": [
    "# Import visualization modules\n",
    "from src.visualizations import BcosPIPNetVisualizer, create_prototype_comparison_grid\n",
    "from src.finetune_classifier import create_scoring_sheet_classifier\n",
    "from src.datasets import SixChannelDataset\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Set matplotlib backend and style\n",
    "plt.style.use('default')\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"All modules imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load_model"
   },
   "outputs": [],
   "source": [
    "# Load the fine-tuned model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Loading model from: {model_path}\")\n",
    "    \n",
    "    # Load checkpoint\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    \n",
    "    # Extract model info\n",
    "    num_classes = checkpoint.get('num_classes', 10)\n",
    "    class_names = checkpoint.get('class_names', [f'Class_{i}' for i in range(num_classes)])\n",
    "    \n",
    "    print(f\"Model info:\")\n",
    "    print(f\"  Number of classes: {num_classes}\")\n",
    "    print(f\"  Classes: {class_names}\")\n",
    "    \n",
    "    # Get pretrained model path from training args\n",
    "    training_args = checkpoint.get('training_args', {})\n",
    "    pretrained_path = training_args.get('pretrained_path', './checkpoints/pretrained_model.pth')\n",
    "    \n",
    "    print(f\"Looking for pretrained model at: {pretrained_path}\")\n",
    "    \n",
    "    # Create model architecture\n",
    "    try:\n",
    "        model = create_scoring_sheet_classifier(\n",
    "            pretrained_path=pretrained_path,\n",
    "            num_classes=num_classes,\n",
    "            freeze_prototypes=True\n",
    "        )\n",
    "        \n",
    "        # Load fine-tuned weights\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        model = model.to(device)\n",
    "        model.eval()\n",
    "        \n",
    "        print(f\"✓ Model loaded successfully!\")\n",
    "        print(f\"  Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "        print(f\"  Number of prototypes: {model.num_prototypes}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error loading model: {e}\")\n",
    "        print(\"Please ensure both the fine-tuned model and original pre-trained model are available.\")\n",
    "        model = None\n",
    "\n",
    "else:\n",
    "    print(f\"Model file not found: {model_path}\")\n",
    "    print(\"Please upload your fine-tuned model first.\")\n",
    "    model = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dataset_setup"
   },
   "source": [
    "## 4. Dataset Setup and Sample Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup_dataset"
   },
   "outputs": [],
   "source": [
    "# Setup dataset for visualization\n",
    "print(\"Setting up CIFAR-10 dataset for visualization...\")\n",
    "\n",
    "# Test transforms (no augmentation for visualization)\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], \n",
    "                       std=[0.2023, 0.1994, 0.2010])\n",
    "])\n",
    "\n",
    "# Load CIFAR-10 test set\n",
    "test_dataset_base = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=test_transform\n",
    ")\n",
    "\n",
    "# Wrap with 6-channel transformation\n",
    "test_dataset = SixChannelDataset(test_dataset_base)\n",
    "\n",
    "# Create dataloader\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=1, shuffle=True, num_workers=2\n",
    ")\n",
    "\n",
    "# CIFAR-10 class names\n",
    "cifar10_classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', \n",
    "                   'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "print(f\"Classes: {cifar10_classes}\")\n",
    "\n",
    "# Get some sample images for visualization\n",
    "sample_images = []\n",
    "sample_labels = []\n",
    "sample_targets = []\n",
    "\n",
    "for i, (img_6ch, label) in enumerate(test_loader):\n",
    "    sample_images.append(img_6ch)\n",
    "    sample_labels.append(label.item())\n",
    "    sample_targets.append(cifar10_classes[label.item()])\n",
    "    \n",
    "    if len(sample_images) >= 10:  # Get 10 samples\n",
    "        break\n",
    "\n",
    "print(f\"Loaded {len(sample_images)} sample images for visualization\")\n",
    "print(f\"Sample classes: {sample_targets[:5]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_visualizer"
   },
   "source": [
    "## 5. Create Visualizer and Test Basic Functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "init_visualizer"
   },
   "outputs": [],
   "source": [
    "# Create visualizer\n",
    "if model is not None:\n",
    "    visualizer = BcosPIPNetVisualizer(model, device=device)\n",
    "    print(\"✓ Visualizer created successfully!\")\n",
    "    \n",
    "    # Test basic functionality\n",
    "    if sample_images:\n",
    "        test_image = sample_images[0]\n",
    "        print(f\"Test image shape: {test_image.shape}\")\n",
    "        \n",
    "        # Test input image visualization\n",
    "        print(\"\\nTesting input image visualization...\")\n",
    "        img_np = visualizer.visualize_input_image(test_image, dataset='cifar10', \n",
    "                                                 title=f\"Test Image: {sample_targets[0]}\")\n",
    "        plt.show()\n",
    "        \n",
    "        # Test prototype activation extraction\n",
    "        print(\"\\nTesting prototype activation extraction...\")\n",
    "        proto_features, pooled_features, locations = visualizer.get_prototype_activations(test_image)\n",
    "        print(f\"Prototype features shape: {proto_features.shape}\")\n",
    "        print(f\"Pooled features shape: {pooled_features.shape}\")\n",
    "        print(f\"Number of active prototypes (>0.1): {(pooled_features > 0.1).sum().item()}\")\n",
    "        \n",
    "        print(\"✓ Basic functionality test passed!\")\n",
    "    else:\n",
    "        print(\"No sample images available for testing\")\n",
    "else:\n",
    "    print(\"Cannot create visualizer - model not loaded\")\n",
    "    visualizer = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "visualization_1"
   },
   "source": [
    "## 6. Visualization 1: Input Image Display\n",
    "\n",
    "Let's start with basic input image visualization, showing how we extract RGB from the 6-channel input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "input_image_viz"
   },
   "outputs": [],
   "source": [
    "# Visualize several input images\n",
    "if visualizer and sample_images:\n",
    "    print(\"Input Image Visualization\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Show first 6 sample images\n",
    "    n_samples = min(6, len(sample_images))\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        # Extract RGB from 6-channel\n",
    "        rgb_tensor = visualizer.extract_rgb_from_6channel(sample_images[i])\n",
    "        img_denorm = visualizer.denormalize_image(rgb_tensor, 'cifar10')\n",
    "        img_np = img_denorm.squeeze(0).permute(1, 2, 0).cpu().numpy()\n",
    "        \n",
    "        axes[i].imshow(img_np)\n",
    "        axes[i].set_title(f'{sample_targets[i]}', fontsize=12, fontweight='bold')\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle('Sample Input Images (RGB extracted from 6-channel)', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Show 6-channel breakdown for one image\n",
    "    print(\"\\n6-Channel Breakdown Example:\")\n",
    "    test_img = sample_images[0]\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "    \n",
    "    # Original RGB channels\n",
    "    rgb_channels = test_img[0, :3].cpu().numpy()\n",
    "    channel_names = ['Red', 'Green', 'Blue']\n",
    "    \n",
    "    for i in range(3):\n",
    "        axes[0, i].imshow(rgb_channels[i], cmap='gray')\n",
    "        axes[0, i].set_title(f'{channel_names[i]} Channel')\n",
    "        axes[0, i].axis('off')\n",
    "    \n",
    "    # Inverse channels\n",
    "    inv_channels = test_img[0, 3:].cpu().numpy()\n",
    "    inv_names = ['1-Red', '1-Green', '1-Blue']\n",
    "    \n",
    "    for i in range(3):\n",
    "        axes[1, i].imshow(inv_channels[i], cmap='gray')\n",
    "        axes[1, i].set_title(f'{inv_names[i]} Channel')\n",
    "        axes[1, i].axis('off')\n",
    "    \n",
    "    plt.suptitle(f'6-Channel Breakdown: {sample_targets[0]}', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Visualizer or sample images not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "visualization_2"
   },
   "source": [
    "## 7. Visualization 2: Learned Part Prototypes\n",
    "\n",
    "Now let's visualize the learned prototypes - showing where in the image each prototype activates most strongly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "prototype_viz"
   },
   "outputs": [],
   "source": [
    "# Visualize prototype activations for individual images\n",
    "if visualizer and sample_images:\n",
    "    print(\"Learned Part Prototypes Visualization\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Show prototype activations for first few images\n",
    "    n_examples = min(3, len(sample_images))\n",
    "    \n",
    "    for i in range(n_examples):\n",
    "        print(f\"\\nExample {i+1}: {sample_targets[i]}\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        # Visualize top prototypes for this image\n",
    "        top_prototypes, prototype_scores = visualizer.visualize_prototype_activations(\n",
    "            sample_images[i], \n",
    "            top_k=9, \n",
    "            dataset='cifar10',\n",
    "            threshold=0.1,\n",
    "            figsize=(15, 10)\n",
    "        )\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "        # Print prototype statistics\n",
    "        if len(top_prototypes) > 0:\n",
    "            print(f\"Top active prototypes:\")\n",
    "            for j, (proto_idx, score) in enumerate(zip(top_prototypes, prototype_scores)):\n",
    "                print(f\"  {j+1}. Prototype {proto_idx}: {score:.3f}\")\n",
    "        else:\n",
    "            print(\"No prototypes above threshold found\")\n",
    "        \n",
    "        print()\n",
    "else:\n",
    "    print(\"Visualizer or sample images not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "prototype_comparison"
   },
   "outputs": [],
   "source": [
    "# Create prototype comparison grid across different images\n",
    "if visualizer and len(sample_images) >= 4:\n",
    "    print(\"\\nPrototype Comparison Across Images\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Select 4 diverse images\n",
    "    comparison_images = sample_images[:4]\n",
    "    comparison_titles = [f\"{sample_targets[i]}\" for i in range(4)]\n",
    "    \n",
    "    fig = create_prototype_comparison_grid(\n",
    "        visualizer, \n",
    "        comparison_images, \n",
    "        titles=comparison_titles,\n",
    "        dataset='cifar10',\n",
    "        figsize=(16, 12)\n",
    "    )\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Each row shows an image and its top 3 prototype activations.\")\n",
    "    print(\"Notice how different prototypes activate for different classes and regions.\")\n",
    "else:\n",
    "    print(\"Need at least 4 sample images for comparison grid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "visualization_3"
   },
   "source": [
    "## 8. Visualization 3: B-cos Spatial Contribution Maps\n",
    "\n",
    "Now let's visualize the B-cos explanations - spatial contribution maps that show which parts of the image contribute positively or negatively to the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bcos_contributions"
   },
   "outputs": [],
   "source": [
    "# Visualize B-cos spatial contributions\n",
    "if visualizer and sample_images:\n",
    "    print(\"B-cos Spatial Contribution Maps\")\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Red regions: Positive contribution to prediction\")\n",
    "    print(\"Blue regions: Negative contribution to prediction\")\n",
    "    print()\n",
    "    \n",
    "    # Show B-cos contributions for first few images\n",
    "    n_examples = min(3, len(sample_images))\n",
    "    \n",
    "    for i in range(n_examples):\n",
    "        print(f\"\\nExample {i+1}: {sample_targets[i]}\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        # Get B-cos contributions\n",
    "        contributions, pred_class, class_score = visualizer.visualize_bcos_contributions(\n",
    "            sample_images[i],\n",
    "            target_class=None,  # Use predicted class\n",
    "            dataset='cifar10',\n",
    "            figsize=(20, 12)\n",
    "        )\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "        # Print prediction info\n",
    "        pred_name = cifar10_classes[pred_class] if pred_class < len(cifar10_classes) else f\"Class {pred_class}\"\n",
    "        true_name = sample_targets[i]\n",
    "        \n",
    "        print(f\"True class: {true_name}\")\n",
    "        print(f\"Predicted class: {pred_name}\")\n",
    "        print(f\"Confidence: {class_score:.3f}\")\n",
    "        print(f\"Correct: {'✓' if pred_name == true_name else '✗'}\")\n",
    "        \n",
    "        if contributions:\n",
    "            print(f\"B-cos layers analyzed: {len(contributions)}\")\n",
    "            for layer_name in contributions.keys():\n",
    "                contrib_map = contributions[layer_name]\n",
    "                pos_contrib = np.sum(contrib_map[contrib_map > 0])\n",
    "                neg_contrib = np.sum(contrib_map[contrib_map < 0])\n",
    "                print(f\"  {layer_name}: +{pos_contrib:.2f}, {neg_contrib:.2f}\")\n",
    "        \n",
    "        print()\n",
    "else:\n",
    "    print(\"Visualizer or sample images not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "comprehensive_viz"
   },
   "source": [
    "## 9. Comprehensive Visualization: All-in-One View\n",
    "\n",
    "Let's create comprehensive visualizations that show input, prototypes, and B-cos contributions all together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "comprehensive_view"
   },
   "outputs": [],
   "source": [
    "# Create comprehensive visualizations\n",
    "if visualizer and sample_images:\n",
    "    print(\"Comprehensive B-cos PIP-Net Visualizations\")\n",
    "    print(\"=\" * 50)\n",
    "    print(\"This view combines:\")\n",
    "    print(\"1. Input image and prediction\")\n",
    "    print(\"2. Top prototype activations\")\n",
    "    print(\"3. B-cos spatial contribution map\")\n",
    "    print()\n",
    "    \n",
    "    # Show comprehensive view for first few images\n",
    "    n_examples = min(3, len(sample_images))\n",
    "    \n",
    "    for i in range(n_examples):\n",
    "        print(f\"\\n{'='*20} Example {i+1}: {sample_targets[i]} {'='*20}\")\n",
    "        \n",
    "        # Create comprehensive visualization\n",
    "        results = visualizer.create_comprehensive_visualization(\n",
    "            sample_images[i],\n",
    "            target_class=None,\n",
    "            dataset='cifar10',\n",
    "            class_names=cifar10_classes,\n",
    "            top_k_prototypes=6,\n",
    "            figsize=(20, 15)\n",
    "        )\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "        # Print detailed results\n",
    "        print(f\"\\nDetailed Analysis:\")\n",
    "        print(f\"  True class: {sample_targets[i]}\")\n",
    "        print(f\"  Predicted: {results['prediction']}\")\n",
    "        print(f\"  Confidence: {results['confidence']:.3f}\")\n",
    "        print(f\"  Correct: {'✓' if results['prediction'] == sample_targets[i] else '✗'}\")\n",
    "        \n",
    "        if results['top_prototypes'] is not None and len(results['top_prototypes']) > 0:\n",
    "            print(f\"\\n  Top Contributing Prototypes:\")\n",
    "            for j, (proto_idx, score) in enumerate(zip(results['top_prototypes'], results['prototype_scores'])):\n",
    "                print(f\"    {j+1}. Prototype {proto_idx}: {score:.3f}\")\n",
    "        \n",
    "        if results['contributions']:\n",
    "            print(f\"\\n  B-cos Contribution Analysis:\")\n",
    "            for layer_name, contrib_map in results['contributions'].items():\n",
    "                pos_contrib = np.sum(contrib_map[contrib_map > 0])\n",
    "                neg_contrib = np.sum(contrib_map[contrib_map < 0])\n",
    "                net_contrib = pos_contrib + neg_contrib\n",
    "                print(f\"    {layer_name}: net={net_contrib:.2f} (+{pos_contrib:.2f}, {neg_contrib:.2f})\")\n",
    "        \n",
    "        print(\"\\n\" + \"-\"*60)\n",
    "else:\n",
    "    print(\"Visualizer or sample images not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "interactive_exploration"
   },
   "source": [
    "## 10. Interactive Exploration\n",
    "\n",
    "Let's create an interactive way to explore different images and their explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "interactive_widget"
   },
   "outputs": [],
   "source": [
    "# Interactive exploration function\n",
    "def explore_image(image_idx, show_prototypes=True, show_bcos=True, top_k=6):\n",
    "    \"\"\"\n",
    "    Explore a specific image with customizable visualization options\n",
    "    \"\"\"\n",
    "    if not visualizer or not sample_images:\n",
    "        print(\"Visualizer or sample images not available\")\n",
    "        return\n",
    "    \n",
    "    if image_idx >= len(sample_images):\n",
    "        print(f\"Image index {image_idx} out of range. Max: {len(sample_images)-1}\")\n",
    "        return\n",
    "    \n",
    "    image_6ch = sample_images[image_idx]\n",
    "    true_class = sample_targets[image_idx]\n",
    "    \n",
    "    print(f\"Exploring Image {image_idx}: {true_class}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    if show_prototypes and show_bcos:\n",
    "        # Comprehensive view\n",
    "        results = visualizer.create_comprehensive_visualization(\n",
    "            image_6ch, dataset='cifar10', class_names=cifar10_classes,\n",
    "            top_k_prototypes=top_k, figsize=(20, 15)\n",
    "        )\n",
    "        \n",
    "    elif show_prototypes:\n",
    "        # Prototype view only\n",
    "        visualizer.visualize_input_image(image_6ch, 'cifar10', f\"Input: {true_class}\")\n",
    "        plt.show()\n",
    "        \n",
    "        top_prototypes, scores = visualizer.visualize_prototype_activations(\n",
    "            image_6ch, top_k=top_k, dataset='cifar10', figsize=(15, 10)\n",
    "        )\n",
    "        \n",
    "    elif show_bcos:\n",
    "        # B-cos view only\n",
    "        visualizer.visualize_input_image(image_6ch, 'cifar10', f\"Input: {true_class}\")\n",
    "        plt.show()\n",
    "        \n",
    "        contributions, pred_class, score = visualizer.visualize_bcos_contributions(\n",
    "            image_6ch, dataset='cifar10', figsize=(18, 12)\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        # Input only\n",
    "        visualizer.visualize_input_image(image_6ch, 'cifar10', f\"Input: {true_class}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Example usage - you can change these parameters\n",
    "print(\"Available images:\")\n",
    "for i, target in enumerate(sample_targets):\n",
    "    print(f\"  {i}: {target}\")\n",
    "\n",
    "print(\"\\nExploring different images:\")\n",
    "print(\"(You can change the image_idx and options below)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "explore_examples"
   },
   "outputs": [],
   "source": [
    "# Explore specific images - modify these as needed\n",
    "if visualizer and sample_images:\n",
    "    \n",
    "    # Example 1: Full comprehensive view\n",
    "    print(\"Example 1: Comprehensive View\")\n",
    "    explore_image(0, show_prototypes=True, show_bcos=True, top_k=6)\n",
    "    \n",
    "    # Example 2: Prototypes only\n",
    "    print(\"\\n\\nExample 2: Prototypes Only\")\n",
    "    explore_image(1, show_prototypes=True, show_bcos=False, top_k=9)\n",
    "    \n",
    "    # Example 3: B-cos contributions only\n",
    "    print(\"\\n\\nExample 3: B-cos Contributions Only\")\n",
    "    explore_image(2, show_prototypes=False, show_bcos=True)\n",
    "    \n",
    "else:\n",
    "    print(\"Visualizer not available for interactive exploration\")\n",
    "\n",
    "# You can add more examples by calling:\n",
    "# explore_image(image_index, show_prototypes=True/False, show_bcos=True/False, top_k=number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "analysis_summary"
   },
   "source": [
    "## 11. Analysis Summary and Insights\n",
    "\n",
    "Let's analyze what we've learned from the visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "analyze_patterns"
   },
   "outputs": [],
   "source": [
    "# Analyze patterns across all sample images\n",
    "if visualizer and sample_images:\n",
    "    print(\"Analysis Summary\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Collect statistics across all samples\n",
    "    all_predictions = []\n",
    "    all_confidences = []\n",
    "    all_active_prototypes = []\n",
    "    correct_predictions = 0\n",
    "    \n",
    "    print(\"Processing all sample images...\")\n",
    "    \n",
    "    for i, (image_6ch, true_class) in enumerate(zip(sample_images, sample_targets)):\n",
    "        with torch.no_grad():\n",
    "            _, pooled_features, _, class_scores = visualizer.model(image_6ch.to(device))\n",
    "        \n",
    "        pred_class = torch.argmax(class_scores, dim=1).item()\n",
    "        confidence = class_scores[0, pred_class].item()\n",
    "        active_protos = (pooled_features > 0.1).sum().item()\n",
    "        \n",
    "        pred_name = cifar10_classes[pred_class] if pred_class < len(cifar10_classes) else f\"Class {pred_class}\"\n",
    "        \n",
    "        all_predictions.append(pred_name)\n",
    "        all_confidences.append(confidence)\n",
    "        all_active_prototypes.append(active_protos)\n",
    "        \n",
    "        if pred_name == true_class:\n",
    "            correct_predictions += 1\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(f\"\\nOverall Statistics:\")\n",
    "    print(f\"  Accuracy: {correct_predictions}/{len(sample_images)} ({100*correct_predictions/len(sample_images):.1f}%)\")\n",
    "    print(f\"  Mean confidence: {np.mean(all_confidences):.3f} ± {np.std(all_confidences):.3f}\")\n",
    "    print(f\"  Mean active prototypes: {np.mean(all_active_prototypes):.1f} ± {np.std(all_active_prototypes):.1f}\")\n",
    "    \n",
    "    # Print per-image results\n",
    "    print(f\"\\nPer-Image Results:\")\n",
    "    print(f\"{'#':<3} {'True':<12} {'Predicted':<12} {'Conf':<6} {'Active':<6} {'Correct'}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for i in range(len(sample_images)):\n",
    "        correct = \"✓\" if all_predictions[i] == sample_targets[i] else \"✗\"\n",
    "        print(f\"{i:<3} {sample_targets[i]:<12} {all_predictions[i]:<12} {all_confidences[i]:<6.3f} {all_active_prototypes[i]:<6} {correct}\")\n",
    "    \n",
    "    # Insights\n",
    "    print(f\"\\nKey Insights:\")\n",
    "    print(f\"1. Prototype Usage: The model uses an average of {np.mean(all_active_prototypes):.1f} prototypes per image\")\n",
    "    print(f\"2. Confidence: Higher confidence often correlates with fewer but more strongly activated prototypes\")\n",
    "    print(f\"3. Interpretability: Each prediction can be explained through prototype activations and B-cos contributions\")\n",
    "    print(f\"4. Spatial Understanding: B-cos maps show exactly which image regions contribute to predictions\")\n",
    "    \n",
    "    # Create summary visualization\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    # Confidence distribution\n",
    "    ax1.hist(all_confidences, bins=10, alpha=0.7, edgecolor='black')\n",
    "    ax1.set_xlabel('Prediction Confidence')\n",
    "    ax1.set_ylabel('Frequency')\n",
    "    ax1.set_title('Distribution of Prediction Confidences')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Active prototypes distribution\n",
    "    ax2.hist(all_active_prototypes, bins=range(min(all_active_prototypes), max(all_active_prototypes)+2), \n",
    "             alpha=0.7, edgecolor='black')\n",
    "    ax2.set_xlabel('Number of Active Prototypes (>0.1)')\n",
    "    ax2.set_ylabel('Frequency')\n",
    "    ax2.set_title('Distribution of Active Prototypes per Image')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"Analysis not available - visualizer or sample images missing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cleanup"
   },
   "source": [
    "## 12. Cleanup and Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cleanup_hooks"
   },
   "outputs": [],
   "source": [
    "# Cleanup hooks to free memory\n",
    "if visualizer:\n",
    "    visualizer.cleanup_hooks()\n",
    "    print(\"✓ Visualization hooks cleaned up\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"B-COS PIP-NET VISUALIZATION SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"✅ Successfully demonstrated:\")\n",
    "print(\"   1. Input Image Visualization\")\n",
    "print(\"      - RGB extraction from 6-channel input\")\n",
    "print(\"      - Proper denormalization for display\")\n",
    "print(\"      - 6-channel breakdown showing [r,g,b,1-r,1-g,1-b]\")\n",
    "print()\n",
    "print(\"   2. Learned Part Prototypes\")\n",
    "print(\"      - Spatial activation heatmaps\")\n",
    "print(\"      - Peak activation locations\")\n",
    "print(\"      - Prototype activation scores\")\n",
    "print(\"      - Top-k prototype selection\")\n",
    "print()\n",
    "print(\"   3. B-cos Spatial Contribution Maps\")\n",
    "print(\"      - Gradient-based explanations\")\n",
    "print(\"      - Positive/negative contribution regions\")\n",
    "print(\"      - Multi-layer contribution analysis\")\n",
    "print(\"      - Target class-specific explanations\")\n",
    "print()\n",
    "print(\"   4. Comprehensive Visualizations\")\n",
    "print(\"      - All-in-one interpretability view\")\n",
    "print(\"      - Interactive exploration capabilities\")\n",
    "print(\"      - Cross-image comparison grids\")\n",
    "print(\"      - Statistical analysis of patterns\")\n",
    "print()\n",
    "print(\"🔬 Key Interpretability Features:\")\n",
    "print(\"   - Each prediction explained through prototype activations\")\n",
    "print(\"   - Spatial understanding of where prototypes activate\")\n",
    "print(\"   - B-cos contributions show pixel-level evidence\")\n",
    "print(\"   - Non-masking approach preserves full spatial information\")\n",
    "print()\n",
    "print(\"💡 Usage Tips:\")\n",
    "print(\"   - Use explore_image() function for interactive analysis\")\n",
    "print(\"   - Adjust top_k parameter to see more/fewer prototypes\")\n",
    "print(\"   - Red regions in B-cos maps = positive evidence\")\n",
    "print(\"   - Blue regions in B-cos maps = negative evidence\")\n",
    "print(\"   - Download this notebook to save your visualization setup\")\n",
    "print()\n",
    "print(\"🎯 The model provides both accurate predictions AND interpretable explanations!\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
