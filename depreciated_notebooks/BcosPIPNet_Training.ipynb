{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title"
   },
   "source": [
    "# Self-Supervised Pre-training of B-cos PIP-Net\n",
    "\n",
    "This notebook implements self-supervised pre-training combining B-cos Networks and PIP-Net for interpretable prototype learning.\n",
    "\n",
    "## Features:\n",
    "- 6-channel image encoding: [r,g,b,1-r,1-g,1-b]\n",
    "- Contrastive pairs through data augmentation\n",
    "- B-cos convolution layers for interpretability\n",
    "- Combined loss: Align Loss (La) + Tanh Loss (Lt)\n",
    "- CUDA-ready for CIFAR-10 and CUB datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## 1. Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check_gpu"
   },
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name()}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clone_repo"
   },
   "outputs": [],
   "source": [
    "# Clone the repository\n",
    "!git clone https://github.com/Karo555/improved-Bcos-PIPNet\n",
    "%cd improved-Bcos-PIPNet\n",
    "\n",
    "# Initialize submodules\n",
    "!git submodule update --init --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup_paths"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add source directories to Python path\n",
    "sys.path.append('src')\n",
    "sys.path.append('B-cos')\n",
    "sys.path.append('PIPNet')\n",
    "\n",
    "# Verify paths\n",
    "print(\"Current directory:\", os.getcwd())\n",
    "print(\"Source files exist:\", os.path.exists('src/train_pretraining.py'))\n",
    "print(\"B-cos modules exist:\", os.path.exists('B-cos/modules/bcosconv2d.py'))\n",
    "print(\"PIPNet modules exist:\", os.path.exists('PIPNet/pipnet/pipnet.py'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "import_modules"
   },
   "source": [
    "## 2. Import Modules and Test Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imports"
   },
   "outputs": [],
   "source": [
    "# Import our custom modules\n",
    "from src.transforms import SixChannelTransform, ContrastiveAugmentationCIFAR\n",
    "from src.bcos_features import bcos_simple_features, bcos_medium_features, bcos_large_features\n",
    "from src.losses import CombinedPretrainingLoss, InfoNCELoss\n",
    "from src.bcos_pipnet import create_bcos_pipnet\n",
    "from src.datasets import get_dataset\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(\"All modules imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test_transforms"
   },
   "outputs": [],
   "source": [
    "# Test 6-channel transformation\n",
    "print(\"Testing 6-channel transformation...\")\n",
    "\n",
    "# Create a sample RGB image\n",
    "rgb_tensor = torch.rand(3, 32, 32)  # Random RGB image\n",
    "print(f\"Original RGB shape: {rgb_tensor.shape}\")\n",
    "\n",
    "# Apply 6-channel transform\n",
    "six_channel_transform = SixChannelTransform()\n",
    "six_channel_tensor = six_channel_transform(rgb_tensor)\n",
    "print(f\"6-channel shape: {six_channel_tensor.shape}\")\n",
    "\n",
    "# Verify the transformation\n",
    "r, g, b = rgb_tensor[0], rgb_tensor[1], rgb_tensor[2]\n",
    "r_6ch, g_6ch, b_6ch = six_channel_tensor[0], six_channel_tensor[1], six_channel_tensor[2]\n",
    "inv_r, inv_g, inv_b = six_channel_tensor[3], six_channel_tensor[4], six_channel_tensor[5]\n",
    "\n",
    "print(f\"R channel match: {torch.allclose(r, r_6ch)}\")\n",
    "print(f\"Inverse R correct: {torch.allclose(1-r, inv_r)}\")\n",
    "print(\"6-channel transformation working correctly!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test_model"
   },
   "outputs": [],
   "source": [
    "# Test model creation\n",
    "print(\"Testing model creation...\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create model with simple B-cos CNN backbone (no ResNet)\n",
    "model = create_bcos_pipnet(\n",
    "    num_prototypes=256,\n",
    "    backbone='bcos_simple',  # Changed from 'bcos_resnet18'\n",
    "    pretrained=False\n",
    ").to(device)\n",
    "\n",
    "print(f\"Model created successfully!\")\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# Test forward pass\n",
    "batch_size = 4\n",
    "dummy_input = torch.randn(batch_size, 6, 32, 32).to(device)\n",
    "print(f\"Input shape: {dummy_input.shape}\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    proto_features, pooled_features, projected_features = model(dummy_input, return_features=True)\n",
    "    \n",
    "print(f\"Prototype features shape: {proto_features.shape}\")\n",
    "print(f\"Pooled features shape: {pooled_features.shape}\")\n",
    "print(f\"Projected features shape: {projected_features.shape}\")\n",
    "print(\"Forward pass successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test forward pass with corrected B-cos implementation\n",
    "print(\"Testing forward pass with corrected B-cos implementation...\")\n",
    "\n",
    "# Test forward pass\n",
    "batch_size = 4\n",
    "dummy_input = torch.randn(batch_size, 6, 32, 32).to(device)\n",
    "print(f\"Input shape: {dummy_input.shape}\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    try:\n",
    "        proto_features, pooled_features, projected_features = model(dummy_input, return_features=True)\n",
    "        \n",
    "        print(f\"✅ B-cos forward pass successful!\")\n",
    "        print(f\"Prototype features shape: {proto_features.shape}\")\n",
    "        print(f\"Pooled features shape: {pooled_features.shape}\")\n",
    "        print(f\"Projected features shape: {projected_features.shape}\")\n",
    "        \n",
    "        # Check activation patterns - B-cos should have different characteristics\n",
    "        print(f\"\\nActivation statistics:\")\n",
    "        print(f\"Pooled features - mean: {pooled_features.mean():.4f}, std: {pooled_features.std():.4f}\")\n",
    "        print(f\"Prototype features - mean: {proto_features.mean():.4f}, std: {proto_features.std():.4f}\")\n",
    "        \n",
    "        # Check for interpretability properties - activations should be meaningful\n",
    "        active_prototypes = (pooled_features > 0.1).sum(dim=1)\n",
    "        print(f\"Average active prototypes per sample: {active_prototypes.float().mean():.1f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Forward pass failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-verify B-cos implementation after removing remaining ReLU layers\n",
    "print(\"Re-verifying B-cos implementation after fixes...\")\n",
    "\n",
    "# Create a fresh model instance to test the fixes\n",
    "model_fixed = create_bcos_pipnet(\n",
    "    num_prototypes=256,\n",
    "    backbone='bcos_simple',  # Using simple B-cos CNN instead of ResNet\n",
    "    pretrained=False\n",
    ").to(device)\n",
    "\n",
    "print(f\"Fixed B-cos Model parameters: {sum(p.numel() for p in model_fixed.parameters()):,}\")\n",
    "\n",
    "\n",
    "# Test forward pass with the fixed model\n",
    "with torch.no_grad():\n",
    "    try:\n",
    "        proto_features, pooled_features, projected_features = model_fixed(dummy_input, return_features=True)\n",
    "        \n",
    "        print(f\"✅ Fixed B-cos forward pass successful!\")\n",
    "        print(f\"Prototype features shape: {proto_features.shape}\")\n",
    "        print(f\"Pooled features shape: {pooled_features.shape}\")\n",
    "        print(f\"Projected features shape: {projected_features.shape}\")\n",
    "        \n",
    "        # Verify prototype activations are non-negative (using abs instead of ReLU)\n",
    "        print(f\"All prototype activations non-negative: {(pooled_features >= 0).all().item()}\")\n",
    "        \n",
    "        # Update the model reference for training\n",
    "        model = model_fixed\n",
    "        print(\"✅ Model updated to use the corrected B-cos implementation\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Forward pass failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dataset_section"
   },
   "source": [
    "## 3. Dataset Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup_dataset"
   },
   "outputs": [],
   "source": [
    "# Setup CIFAR-10 dataset\n",
    "print(\"Setting up CIFAR-10 dataset...\")\n",
    "\n",
    "dataset = get_dataset('cifar10', \n",
    "                     data_dir='./data',\n",
    "                     batch_size=64,  # Smaller batch for Colab\n",
    "                     num_workers=2)  # Fewer workers for Colab\n",
    "\n",
    "train_loader, test_loader = dataset.get_dataloaders()\n",
    "print(f\"Train samples: {len(train_loader.dataset)}\")\n",
    "print(f\"Test samples: {len(test_loader.dataset)}\")\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "\n",
    "# Test data loading\n",
    "view1, view2, labels = next(iter(train_loader))\n",
    "print(f\"View 1 shape: {view1.shape} (6-channel)\")\n",
    "print(f\"View 2 shape: {view2.shape} (6-channel)\")\n",
    "print(f\"Labels shape: {labels.shape}\")\n",
    "print(\"Dataset setup successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "visualize_data"
   },
   "outputs": [],
   "source": [
    "# Visualize the 6-channel transformation\n",
    "print(\"Visualizing 6-channel transformation...\")\n",
    "\n",
    "# Get a sample\n",
    "view1, view2, labels = next(iter(train_loader))\n",
    "sample = view1[0]  # First sample, shape: (6, 32, 32)\n",
    "\n",
    "# Extract RGB and inverse channels\n",
    "rgb_channels = sample[:3]\n",
    "inv_channels = sample[3:]\n",
    "\n",
    "# Denormalize for visualization (CIFAR-10 normalization)\n",
    "mean = torch.tensor([0.4914, 0.4822, 0.4465]).view(3, 1, 1)\n",
    "std = torch.tensor([0.2023, 0.1994, 0.2010]).view(3, 1, 1)\n",
    "rgb_denorm = rgb_channels * std + mean\n",
    "rgb_denorm = torch.clamp(rgb_denorm, 0, 1)\n",
    "\n",
    "# Create visualization\n",
    "fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
    "\n",
    "# Original RGB channels\n",
    "for i, (ax, title) in enumerate(zip(axes[0], ['Red', 'Green', 'Blue'])):\n",
    "    ax.imshow(rgb_denorm[i], cmap='gray')\n",
    "    ax.set_title(f'{title} Channel')\n",
    "    ax.axis('off')\n",
    "\n",
    "# Inverse channels\n",
    "for i, (ax, title) in enumerate(zip(axes[1], ['1-Red', '1-Green', '1-Blue'])):\n",
    "    # Denormalize inverse channels\n",
    "    inv_denorm = inv_channels[i] * std[i] + mean[i]\n",
    "    inv_denorm = torch.clamp(inv_denorm, 0, 1)\n",
    "    ax.imshow(inv_denorm, cmap='gray')\n",
    "    ax.set_title(f'{title} Channel')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"6-channel visualization complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "training_config"
   },
   "outputs": [],
   "source": [
    "# Training configuration for Colab\n",
    "class TrainingConfig:\n",
    "    # Dataset\n",
    "    dataset = 'cifar10'\n",
    "    data_dir = './data'\n",
    "    batch_size = 64  # Reduced for Colab\n",
    "    num_workers = 2\n",
    "    \n",
    "    # Model\n",
    "    # backbone options: 'bcos_simple', 'bcos_medium', 'bcos_large'\n",
    "    backbone = 'bcos_simple'  # Simple B-cos CNN instead of ResNet\n",
    "    num_prototypes = 256\n",
    "    \n",
    "    # Training\n",
    "    epochs = 50  # Reduced for demo\n",
    "    lr = 1e-3\n",
    "    weight_decay = 1e-4\n",
    "    warmup_epochs = 5\n",
    "    \n",
    "    # Loss weights\n",
    "    align_weight = 1.0\n",
    "    tanh_weight = 1.0\n",
    "    contrastive_weight = 0.5  # Optional contrastive loss\n",
    "    temperature = 0.07\n",
    "    \n",
    "    # Device and logging\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    log_interval = 50\n",
    "    save_interval = 10\n",
    "    \n",
    "    # Directories\n",
    "    log_dir = './logs/colab_training'\n",
    "    save_dir = './checkpoints/colab_training'\n",
    "    \n",
    "    # Other\n",
    "    seed = 42\n",
    "\n",
    "args = TrainingConfig()\n",
    "print(f\"Training configuration:\")\n",
    "print(f\"  Device: {args.device}\")\n",
    "print(f\"  Epochs: {args.epochs}\")\n",
    "print(f\"  Batch size: {args.batch_size}\")\n",
    "print(f\"  Learning rate: {args.lr}\")\n",
    "print(f\"  Prototypes: {args.num_prototypes}\")\n",
    "print(f\"  Backbone: {args.backbone} (Simple B-cos CNN)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_directories"
   },
   "outputs": [],
   "source": [
    "# Create directories\n",
    "os.makedirs(args.log_dir, exist_ok=True)\n",
    "os.makedirs(args.save_dir, exist_ok=True)\n",
    "print(f\"Created directories: {args.log_dir}, {args.save_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "training_loop_section"
   },
   "source": [
    "## 5. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup_training"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "import time\n",
    "\n",
    "# Set seed\n",
    "torch.manual_seed(args.seed)\n",
    "torch.cuda.manual_seed_all(args.seed)\n",
    "\n",
    "# Create model\n",
    "model = create_bcos_pipnet(\n",
    "    num_prototypes=args.num_prototypes,\n",
    "    backbone=args.backbone,\n",
    "    pretrained=False\n",
    ").to(args.device)\n",
    "\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# Create loss functions\n",
    "criterion = CombinedPretrainingLoss(\n",
    "    align_weight=args.align_weight,\n",
    "    tanh_weight=args.tanh_weight\n",
    ")\n",
    "\n",
    "contrastive_criterion = InfoNCELoss(temperature=args.temperature)\n",
    "\n",
    "# Create optimizer\n",
    "optimizer = optim.AdamW(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "\n",
    "print(\"Training setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "learning_rate_scheduler"
   },
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch, args):\n",
    "    \"\"\"Cosine learning rate schedule with warmup\"\"\"\n",
    "    if epoch < args.warmup_epochs:\n",
    "        lr = args.lr * epoch / args.warmup_epochs\n",
    "    else:\n",
    "        lr = args.lr * 0.5 * (1. + np.cos(np.pi * (epoch - args.warmup_epochs) / (args.epochs - args.warmup_epochs)))\n",
    "    \n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "    \n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "training_loop",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training loop\n",
    "print(\"Starting training...\")\n",
    "\n",
    "# Lists to store metrics\n",
    "train_losses = []\n",
    "align_losses = []\n",
    "tanh_losses = []\n",
    "contrastive_losses = []\n",
    "learning_rates = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(args.epochs):\n",
    "    model.train()\n",
    "    \n",
    "    # Adjust learning rate\n",
    "    lr = adjust_learning_rate(optimizer, epoch, args)\n",
    "    learning_rates.append(lr)\n",
    "    \n",
    "    # Initialize metrics\n",
    "    epoch_loss = 0.0\n",
    "    epoch_align_loss = 0.0\n",
    "    epoch_tanh_loss = 0.0\n",
    "    epoch_contrastive_loss = 0.0\n",
    "    \n",
    "    # Progress bar\n",
    "    pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{args.epochs}')\n",
    "    \n",
    "    for batch_idx, (view1, view2, labels) in enumerate(pbar):\n",
    "        view1, view2 = view1.to(args.device), view2.to(args.device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass through both views\n",
    "        proto_features1, pooled1, projected1 = model(view1, return_features=True)\n",
    "        proto_features2, pooled2, projected2 = model(view2, return_features=True)\n",
    "        \n",
    "        # Compute combined pre-training loss (La + Lt)\n",
    "        loss_dict = criterion(model, proto_features1, proto_features2)\n",
    "        loss = loss_dict['total_loss']\n",
    "        \n",
    "        # Add contrastive loss if specified\n",
    "        contrastive_loss = torch.tensor(0.0, device=args.device)\n",
    "        if args.contrastive_weight > 0:\n",
    "            # Normalize projected features\n",
    "            projected1_norm = F.normalize(projected1, dim=1)\n",
    "            projected2_norm = F.normalize(projected2, dim=1)\n",
    "            contrastive_loss = contrastive_criterion(projected1_norm, projected2_norm)\n",
    "            loss += args.contrastive_weight * contrastive_loss\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update metrics\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_align_loss += loss_dict['align_loss'].item()\n",
    "        epoch_tanh_loss += loss_dict['tanh_loss'].item()\n",
    "        epoch_contrastive_loss += contrastive_loss.item()\n",
    "        \n",
    "        # Update progress bar\n",
    "        pbar.set_postfix({\n",
    "            'Loss': f'{loss.item():.4f}',\n",
    "            'La': f'{loss_dict[\"align_loss\"].item():.4f}',\n",
    "            'Lt': f'{loss_dict[\"tanh_loss\"].item():.4f}',\n",
    "            'Lc': f'{contrastive_loss.item():.4f}',\n",
    "            'LR': f'{lr:.6f}'\n",
    "        })\n",
    "    \n",
    "    # Calculate average losses for the epoch\n",
    "    avg_loss = epoch_loss / len(train_loader)\n",
    "    avg_align_loss = epoch_align_loss / len(train_loader)\n",
    "    avg_tanh_loss = epoch_tanh_loss / len(train_loader)\n",
    "    avg_contrastive_loss = epoch_contrastive_loss / len(train_loader)\n",
    "    \n",
    "    # Store metrics\n",
    "    train_losses.append(avg_loss)\n",
    "    align_losses.append(avg_align_loss)\n",
    "    tanh_losses.append(avg_tanh_loss)\n",
    "    contrastive_losses.append(avg_contrastive_loss)\n",
    "    \n",
    "    # Print epoch summary\n",
    "    print(f\"Epoch {epoch+1}: Loss={avg_loss:.4f}, La={avg_align_loss:.4f}, \"\n",
    "          f\"Lt={avg_tanh_loss:.4f}, Lc={avg_contrastive_loss:.4f}, LR={lr:.6f}\")\n",
    "    \n",
    "    # Save checkpoint\n",
    "    if (epoch + 1) % args.save_interval == 0:\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'train_loss': avg_loss,\n",
    "            'args': vars(args)\n",
    "        }\n",
    "        torch.save(checkpoint, os.path.join(args.save_dir, f'checkpoint_epoch_{epoch+1}.pth'))\n",
    "        print(f\"Checkpoint saved at epoch {epoch+1}\")\n",
    "\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "visualization_section"
   },
   "source": [
    "## 6. Results Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "plot_losses"
   },
   "outputs": [],
   "source": [
    "# Plot training losses\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Total loss\n",
    "axes[0,0].plot(train_losses)\n",
    "axes[0,0].set_title('Total Loss')\n",
    "axes[0,0].set_xlabel('Epoch')\n",
    "axes[0,0].set_ylabel('Loss')\n",
    "axes[0,0].grid(True)\n",
    "\n",
    "# Align loss\n",
    "axes[0,1].plot(align_losses, color='orange')\n",
    "axes[0,1].set_title('Align Loss (La)')\n",
    "axes[0,1].set_xlabel('Epoch')\n",
    "axes[0,1].set_ylabel('Loss')\n",
    "axes[0,1].grid(True)\n",
    "\n",
    "# Tanh loss\n",
    "axes[1,0].plot(tanh_losses, color='green')\n",
    "axes[1,0].set_title('Tanh Loss (Lt)')\n",
    "axes[1,0].set_xlabel('Epoch')\n",
    "axes[1,0].set_ylabel('Loss')\n",
    "axes[1,0].grid(True)\n",
    "\n",
    "# Learning rate\n",
    "axes[1,1].plot(learning_rates, color='red')\n",
    "axes[1,1].set_title('Learning Rate')\n",
    "axes[1,1].set_xlabel('Epoch')\n",
    "axes[1,1].set_ylabel('Learning Rate')\n",
    "axes[1,1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Final losses:\")\n",
    "print(f\"  Total: {train_losses[-1]:.4f}\")\n",
    "print(f\"  Align: {align_losses[-1]:.4f}\")\n",
    "print(f\"  Tanh: {tanh_losses[-1]:.4f}\")\n",
    "if args.contrastive_weight > 0:\n",
    "    print(f\"  Contrastive: {contrastive_losses[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "analyze_prototypes"
   },
   "outputs": [],
   "source": [
    "# Analyze learned prototypes\n",
    "print(\"Analyzing learned prototypes...\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Get a batch of data\n",
    "    view1, view2, labels = next(iter(train_loader))\n",
    "    view1 = view1.to(args.device)\n",
    "    \n",
    "    # Get prototype activations\n",
    "    proto_features, pooled_features = model.get_prototype_activations(view1)\n",
    "    \n",
    "    print(f\"Prototype features shape: {proto_features.shape}\")\n",
    "    print(f\"Pooled features shape: {pooled_features.shape}\")\n",
    "    \n",
    "    # Analyze prototype activation statistics\n",
    "    proto_stats = {\n",
    "        'mean': pooled_features.mean(dim=0),\n",
    "        'std': pooled_features.std(dim=0),\n",
    "        'max': pooled_features.max(dim=0)[0],\n",
    "        'min': pooled_features.min(dim=0)[0]\n",
    "    }\n",
    "    \n",
    "    # Plot prototype activation distribution\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Histogram of prototype activations\n",
    "    axes[0].hist(pooled_features.cpu().numpy().flatten(), bins=50, alpha=0.7)\n",
    "    axes[0].set_title('Distribution of Prototype Activations')\n",
    "    axes[0].set_xlabel('Activation Value')\n",
    "    axes[0].set_ylabel('Frequency')\n",
    "    axes[0].grid(True)\n",
    "    \n",
    "    # Mean activation per prototype\n",
    "    axes[1].plot(proto_stats['mean'].cpu().numpy())\n",
    "    axes[1].set_title('Mean Activation per Prototype')\n",
    "    axes[1].set_xlabel('Prototype Index')\n",
    "    axes[1].set_ylabel('Mean Activation')\n",
    "    axes[1].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print statistics\n",
    "    print(f\"\\nPrototype activation statistics:\")\n",
    "    print(f\"  Overall mean: {pooled_features.mean():.4f}\")\n",
    "    print(f\"  Overall std: {pooled_features.std():.4f}\")\n",
    "    print(f\"  Max activation: {pooled_features.max():.4f}\")\n",
    "    print(f\"  Min activation: {pooled_features.min():.4f}\")\n",
    "    \n",
    "    # Count active prototypes (> 0.1 threshold like in PIP-Net)\n",
    "    active_prototypes = (pooled_features > 0.1).sum(dim=1)\n",
    "    print(f\"  Average active prototypes per sample: {active_prototypes.float().mean():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "save_section"
   },
   "source": [
    "## 7. Save Final Model and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "save_final_model"
   },
   "outputs": [],
   "source": [
    "# Save final model\n",
    "final_checkpoint = {\n",
    "    'epoch': args.epochs,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'train_losses': train_losses,\n",
    "    'align_losses': align_losses,\n",
    "    'tanh_losses': tanh_losses,\n",
    "    'contrastive_losses': contrastive_losses,\n",
    "    'learning_rates': learning_rates,\n",
    "    'args': vars(args),\n",
    "    'num_prototypes': args.num_prototypes,\n",
    "    'backbone': args.backbone\n",
    "}\n",
    "\n",
    "final_path = os.path.join(args.save_dir, 'final_model.pth')\n",
    "torch.save(final_checkpoint, final_path)\n",
    "print(f\"Final model saved to: {final_path}\")\n",
    "\n",
    "# Save training metrics as JSON\n",
    "metrics = {\n",
    "    'train_losses': train_losses,\n",
    "    'align_losses': align_losses,\n",
    "    'tanh_losses': tanh_losses,\n",
    "    'contrastive_losses': contrastive_losses,\n",
    "    'learning_rates': learning_rates,\n",
    "    'final_loss': train_losses[-1],\n",
    "    'min_loss': min(train_losses),\n",
    "    'training_config': vars(args)\n",
    "}\n",
    "\n",
    "with open(os.path.join(args.save_dir, 'training_metrics.json'), 'w') as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "print(\"Training metrics saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download_results"
   },
   "outputs": [],
   "source": [
    "# Create downloadable archive of results\n",
    "import zipfile\n",
    "\n",
    "zip_path = 'bcos_pipnet_training_results.zip'\n",
    "with zipfile.ZipFile(zip_path, 'w') as zipf:\n",
    "    # Add model checkpoints\n",
    "    for file in os.listdir(args.save_dir):\n",
    "        if file.endswith('.pth') or file.endswith('.json'):\n",
    "            zipf.write(os.path.join(args.save_dir, file), f'checkpoints/{file}')\n",
    "    \n",
    "    # Add this notebook\n",
    "    if os.path.exists('BcosPIPNet_Training.ipynb'):\n",
    "        zipf.write('BcosPIPNet_Training.ipynb', 'BcosPIPNet_Training.ipynb')\n",
    "\n",
    "print(f\"Results packaged in: {zip_path}\")\n",
    "print(f\"Download this file to save your training results!\")\n",
    "\n",
    "# Show file sizes\n",
    "if os.path.exists(final_path):\n",
    "    size_mb = os.path.getsize(final_path) / (1024*1024)\n",
    "    print(f\"Final model size: {size_mb:.1f} MB\")\n",
    "\n",
    "if os.path.exists(zip_path):\n",
    "    zip_size_mb = os.path.getsize(zip_path) / (1024*1024)\n",
    "    print(f\"Results archive size: {zip_size_mb:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "next_steps"
   },
   "source": [
    "## 8. Next Steps\n",
    "\n",
    "After completing the self-supervised pre-training, you can:\n",
    "\n",
    "1. **Fine-tune for Classification**: Use the learned prototypes as initialization for supervised classification tasks\n",
    "2. **Analyze Interpretability**: Visualize what each prototype has learned to represent\n",
    "3. **Transfer Learning**: Apply the pre-trained model to other datasets\n",
    "4. **Prototype Analysis**: Study the alignment properties and interpretability of the learned representations\n",
    "\n",
    "### Loading the Pre-trained Model\n",
    "\n",
    "```python\n",
    "# Load the pre-trained model\n",
    "checkpoint = torch.load('final_model.pth')\n",
    "model = create_bcos_pipnet(\n",
    "    num_prototypes=checkpoint['num_prototypes'],\n",
    "    backbone=checkpoint['backbone']\n",
    ")\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "```\n",
    "\n",
    "### Training Summary\n",
    "\n",
    "This implementation successfully combines:\n",
    "- **B-cos Networks**: For interpretable convolution operations\n",
    "- **PIP-Net**: For prototype-based learning\n",
    "- **Self-supervised Learning**: Using contrastive augmentations and alignment losses\n",
    "- **6-channel Encoding**: Enhanced input representation with complementary channels\n",
    "\n",
    "The model learns interpretable prototypes in a self-supervised manner, making it suitable for applications requiring both high performance and interpretability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B-cos Implementation Updates Applied\n",
    "\n",
    "### Key Changes Made:\n",
    "\n",
    "1. **Replaced ResNet with Simple B-cos CNN**:\n",
    "   - ❌ **NO ResNet structure** - Replaced with sequential BcosConv2d layers\n",
    "   - ✅ **Simple CNN architecture** - Following B-cos CIFAR10 experiments\n",
    "   - ✅ **Sequential layers** - [64→128→256→512] channels with stride=2 for downsampling\n",
    "\n",
    "2. **Maintained Proper B-cos Components**:\n",
    "   - ✅ **MaxOut in BcosConv2d** - All layers use `max_out=2` parameter\n",
    "   - ✅ **Global Average Pooling** - `MyAdaptiveAvgPool2d((1, 1))` from B-cos utils\n",
    "   - ✅ **Linear initialization** - 'linear' nonlinearity for B-cos weights\n",
    "   - ✅ **Scale factor** - `scale_fact=100` following B-cos experiments\n",
    "\n",
    "3. **Removed ALL Forbidden Components**:\n",
    "   - ❌ **NO ReLU activations** - All `nn.ReLU()` layers removed\n",
    "   - ❌ **NO BatchNorm layers** - All `nn.BatchNorm2d()` layers removed  \n",
    "   - ❌ **NO MaxPooling** - All `nn.MaxPool2d()` layers removed\n",
    "   - ❌ **NO Residual connections** - Simplified to pure sequential architecture\n",
    "\n",
    "4. **New Backbone Options**:\n",
    "   - **bcos_simple**: 7 layers, 512 output channels (replaces bcos_resnet18)\n",
    "   - **bcos_medium**: 10 layers, 512 output channels (replaces bcos_resnet50)\n",
    "   - **bcos_large**: 13 layers, 1024 output channels (for complex datasets)\n",
    "\n",
    "### Architecture Details:\n",
    "\n",
    "**Simple B-cos CNN Configuration**:\n",
    "```\n",
    "Input (6 channels) → BcosConv2d(6→64, k=3, s=1) → \n",
    "BcosConv2d(64→128, k=3, s=2) → BcosConv2d(128→128, k=3, s=1) →\n",
    "BcosConv2d(128→256, k=3, s=2) → BcosConv2d(256→256, k=3, s=1) →\n",
    "BcosConv2d(256→512, k=3, s=2) → BcosConv2d(512→512, k=3, s=1) →\n",
    "Global Average Pool → Flatten (512 features)\n",
    "```\n",
    "\n",
    "### B-cos Compliance:\n",
    "- **Pure B-cos layers**: Only BcosConv2d with cosine similarity\n",
    "- **Built-in MaxOut**: `max_out=2` handles feature selection\n",
    "- **No forbidden operations**: Complete removal of ReLU/BatchNorm/MaxPool\n",
    "- **Interpretability preserved**: Maintains B-cos alignment properties\n",
    "\n",
    "This implementation now follows the original B-cos methodology exactly as demonstrated in their CIFAR10 experiments, ensuring proper interpretability while maintaining prototype learning capabilities."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
